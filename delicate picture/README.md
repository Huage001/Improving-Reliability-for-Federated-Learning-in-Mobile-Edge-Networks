

# Improving-Reliability-for-Federated-Learning-in-Mobile-Edge-Networks

> Note: in this README.md, we denote "a distribution / a number" the result of get the distribution and then divide it by the number.

## Figure 1

* our main graph: average error rate - number of devices

* device error rate: uniform distribution in [0,0.2]

* data size: uniform distribution in [0,1]

* data ratio: 0.4

* To be more specific: 这张图描绘了三种策略下，平均错误率与候选设备数的关系。其中，设备错误率在[0,0.2]区间内取均匀分布，数据量在[0,1]区间内均匀分布，规定至少选择40%的数据量。我们的结果在均匀分布下对比其他两种有明显提升，可以说明我们的算法在平均表现上的优越性

  > raw data:
  >
  > ```python
  > [0.10024496123659585, 0.09354314313935586, 0.07407808081193545, 0.08919712807191389, 0.10413952052243239, 0.113505231508731, 0.08153949613570159, 0.1044618424014144, 0.12443843489715589, 0.15497076074235985, 0.1086634599692958, 0.09467884915877307, 0.15455938528558694, 0.24319607767593315, 0.23506213294938702, 0.15293916997841203, 0.17739542410837603, 0.24449711936870688, 0.26178895437622396, 0.23677268838571958, 0.3133531328090492, 0.22401339718666707, 0.2854629367209235, 0.35804499248222976, 0.4172276623314521, 0.37263737660794094, 0.5214294602751846, 0.4202032807479467][0.12240443473185927, 0.10766173677020616, 0.13150386599936545, 0.1327995714369105, 0.14597495811500197, 0.1638217534958707, 0.16382926857460067, 0.14060840777023523, 0.17115427302800804, 0.16063207583772776, 0.16648446798960967, 0.17536096745502314, 0.21009987683108636, 0.20054415051900015, 0.20742271569094445, 0.2191758883277369, 0.24810432123124423, 0.26879624941249664, 0.24705958568505237, 0.2937189184483314, 0.31133284770977826, 0.3542021132474643, 0.35993107845342487, 0.4324831483222513, 0.4133678737913164, 0.4646442125926673, 0.5201087002424643, 0.5019294548896294][0.10035438921980393, 0.11493885343659774, 0.09472707501058339, 0.12318993050975395, 0.09513239866033366, 0.1231647001560773, 0.1336497330754065, 0.15639100387275856, 0.12480254264195911, 0.16605425195904067, 0.14161592672040074, 0.19761129076813383, 0.17950690897301783, 0.2823773957942145, 0.36026278002574863, 0.252658128417247, 0.3049320130751769, 0.2869863719580523, 0.42706316005974154, 0.36635228380268475, 0.4055453261716603, 0.42144973465072183, 0.43672797804102137, 0.4145279384810011, 0.44643013042565227, 0.48669902637160944, 0.6600504097031041, 0.4623571733384382]
  > ```

## Figure 2

* our main graph: average error rate - number of devices

* device error rate: F distribution with parameter (1,1) / 5

* data size: F distribution with parameter (1,1)

* data ratio: 0.5

* To be more specific: 这张图描绘了三种策略下，平均错误率与候选设备数的关系。其中，设备错误率取参数为(1,1)/5的F分布（更符合当今科技与国民经济条件下，边缘设备的错误分布），数据量取参数为(1,1)的F分布（因为现实情况下，设备拥有的数据量有偏置，即：大多数设备拥有的数据规模比较小，只有一小部分设备拥有的数据量大），规定至少选择50%的数据量。我们的结果在F分布下对比其他两种有更加明显的提升，可以说明我们的算法在现实意义下的优越性

  > raw data:
  >
  > ```python
  > [0.04169161128299922, 0.03320371425168285, 0.09436282901013186, 0.08161419298421738, 0.053684906191328464, 0.11516547742070485, 0.06580764562334504, 0.07225244100643688, 0.06499096375997857, 0.11973315926372971, 0.06035669461064326, 0.057615177912121326, 0.07779657989574015, 0.0768038711464363, 0.07401188273343538, 0.09667443671091422, 0.07884895167400298, 0.1339285502623831, 0.12081728602887384, 0.13572411916707122, 0.18470627273699988, 0.11865626370134512, 0.29076025649973075, 0.16443241652359672, 0.16003710213107977, 0.12240043256901986, 0.17314224788252977, 0.252368356560792, 0.2934017391849454, 0.17085990905429155, 0.11177884192505397, 0.2513899665706227, 0.2464680788622693, 0.3282271350965035, 0.24580462067820413, 0.17624452821611156, 0.41407201492423373, 0.24856835249773349][0.054009626389345734, 0.1192346871444846, 0.13471164165563632, 0.1243032205414241, 0.1756136441947413, 0.19563707026216517, 0.15842920708270078, 0.19341876539023561, 0.10946533203607549, 0.13938144810463582, 0.1367756400705873, 0.12354055707206542, 0.2214623801272389, 0.1333725115490742, 0.10146957216191477, 0.18713388244503174, 0.22533863699280157, 0.23766155326764832, 0.23249612181567278, 0.14767870746569187, 0.3221809506562572, 0.16393580556532222, 0.3977740083320679, 0.34537972727610694, 0.23472937481366749, 0.21209557023545952, 0.43170508942703895, 0.3699395260681242, 0.4869075702898413, 0.19215774642499764, 0.3287547150981947, 0.2202278217068585, 0.28204225847354975, 0.3624732524723895, 0.3229063810530195, 0.2912710328248892, 0.42157213086310197, 0.3050637352360973][0.06952076049945813, 0.041720004094942545, 0.05409020359665723, 0.09876641477315058, 0.22027830708553658, 0.09616701555664256, 0.07333654249485479, 0.12383918940051, 0.10608692304605713, 0.08260216578453419, 0.07745852900231927, 0.127712966934398, 0.11724805789870427, 0.06671167627679, 0.08089215917357324, 0.15750542182481206, 0.0870928281646653, 0.1709274577806848, 0.20673898915459005, 0.16436163813134388, 0.3285201868923452, 0.11744384731810179, 0.31323554530553216, 0.22185944050322504, 0.13995998930937467, 0.15965626404255281, 0.3594785764697133, 0.30570909556754533, 0.32967399953431487, 0.22006357994793047, 0.22137311106157923, 0.15007667044802964, 0.2652109178576656, 0.39348669415859716, 0.3307438316142932, 0.24461013775010382, 0.46614560590339654, 0.36185767699079385]
  > ```

## Figure 3

* average error rate performance - data ratio

* device error rate: uniform distribution in [0,0.2]

* data size: uniform distribution in [0,1]

* online device numbers: 25

* To be more specific: 这张图描绘了三种策略下，平均错误率与至少选择多少比例数据量的关系。其中，设备错误率在[0,0.2]区间内取均匀分布，数据量在[0,1]区间内均匀分布，候选设备数为25（对于一个边缘服务器而言，是一个合理的数值）。我们的结果在均匀分布下对比其他两种有明显提升，可以说明我们的算法在平均表现上的优越性

  > raw data:
  >
  > ```python
  > [0.0708120720763593, 0.0699684078215062, 0.0879910310359461, 0.12212216457777965, 0.10668022495297451, 0.14919226538396382, 0.19846097250846242, 0.24450579215398333, 0.2548913107751952, 0.23672620111544954, 0.2790945332145305, 0.4461736648509766, 0.4632798318621548, 0.7188186817360114, 0.7319278103447062, 0.8257550158450275, 0.8534208190107441, 0.8704555365287586, 0.8728621086677952, 0.8872448891672862][0.15079730402041508, 0.1478196651740949, 0.15784634224708735, 0.1656864722179789, 0.19655352673749912, 0.18142862889948846, 0.19208471145071288, 0.23308163579872448, 0.28303715834830745, 0.3134423165815039, 0.40018702991933763, 0.4380625823443755, 0.503192951237532, 0.6969852681332256, 0.7119786812725465, 0.8066795767722468, 0.8188929349016556, 0.850367818425358, 0.8622333794530418, 0.8797120689007427][0.13224917061777602, 0.10969509777286912, 0.10172033957275864, 0.20233705191188775, 0.21235494505538055, 0.3214900348019043, 0.25409058311677096, 0.28720984141705425, 0.35634988451721483, 0.31533945144637776, 0.38921887184666437, 0.4244573776430511, 0.587952321375666, 0.726094519711277, 0.7278260516243563, 0.7996433261929435, 0.8716078056082063, 0.8426618094991476, 0.8606217507924601, 0.8868187142029432]
  > ```

## Figure 4

- average error rate performance - data ratio

- device error rate: F distribution with parameter (1,1) / 5

- data size: F distribution with parameter (1,1)

- online device numbers: 25

- To be more specific: 这张图描绘了三种策略下，平均错误率与至少选择多少比例数据量的关系。其中，设备错误率取参数为(1,1)/5的F分布（更符合当今科技与国民经济条件下，边缘设备的错误分布），数据量取参数为(1,1)的F分布（因为现实情况下，设备拥有的数据量有偏置，即：大多数设备拥有的数据规模比较小，只有一小部分设备拥有的数据量大），候选设备数为25（对于一个边缘服务器而言，是一个合理的数值）。我们的结果在F分布下对比其他两种有更加明显的提升，可以说明我们的算法在现实意义下的优越性

  > raw data:
  >
  > ```python
  > [0.021967797781402554, 0.020922567766596963, 0.030838414144104986, 0.025297625478038, 0.015765497072154223, 0.023023441328102655, 0.026213319073492492, 0.04348281177148512, 0.03732709562489976, 0.06980476851154574, 0.031566294851538425, 0.10542600592028017, 0.06402528566204266, 0.1848931964696335, 0.14145218296047318, 0.14274916957341593, 0.21018353402606996, 0.25722811747520224, 0.3687707080599728, 0.4892859390957988][0.03596909117312512, 0.04854049393002029, 0.06287771685884394, 0.03232910960421073, 0.026543032854965128, 0.06448830252471156, 0.09679959905535684, 0.08055293217754773, 0.0454937907731813, 0.06594378409171575, 0.07600651345094475, 0.1358139387272717, 0.10598154508909843, 0.17322260105714155, 0.15028947867410414, 0.20544845913603665, 0.2553564903404872, 0.3023456473494287, 0.530958414848703, 0.49871626020754045][0.027409917259274157, 0.019113219633357152, 0.05905637246504443, 0.02459354165668893, 0.0691577002624458, 0.046075999106214974, 0.05273203538291769, 0.03712011583720495, 0.03572977266978045, 0.07056882539745943, 0.07623281511913085, 0.06377904194654674, 0.09269235019869272, 0.19239645167441216, 0.16594898900603075, 0.23766569581113967, 0.19620125592030715, 0.32102292598667354, 0.5013689477210479, 0.5320696522292041]
  > ```

## Figure 5

* best error rate performance upon different distributions

* For uniform distribution, the device error ranges are:

  * [0,1] / 5
  * [1,2] / 5
  * [2,3] / 5

  and the data size ranges are:

  	* [0,1]
  	* [1,2]
  	* [2,3]

 * For F distribution, the device error ranges are:

   - (1,1) / 5
   - (8,3) / 5
   - (20,20) / 5

   and the data size ranges are:

   - (1,1)
   - (8,3)
   - (20,20)

* For zipf distribution, the device error ranges are:

  - 1.5 / 100
  - 2 / 100
  - 3 / 100

  and the data size ranges are:

  - 1.5
  - 2
  - 3

* data ratio: 0.5

* online device number: 25

* To be more specific: 这张图以及下面两张图描绘了三种策略下，错误率在不同数据量和设备错误率分布的条件下的情况。无论是均匀、F分布以及Zipf分布（Zipf分布可给引文）下，我们的效果都很显著。说明我们的算法具有极高的泛化能力和现实意义。

  > raw data:
  >
  > ```python
  > [0.18451033254200727, 0.509114653639504, 0.5560844180450155, 0.42243834506256284, 0.2719958895747374, 0.10035085542339557, 0.051088403517242136, 0.024199785904578892, 0.37954699271918446][0.32875670689200803, 0.6086738482588784, 0.7382824842164204, 0.6130157343970889, 0.6212077949931287, 0.45392446637397366, 0.9030690004752815, 0.051088403517242136, 0.7310840606224345][0.32838474734691936, 0.8838179462737625, 0.6303164948057695, 0.8544348484294957, 0.8296888376996794, 0.6341124146012141, 0.2721021819721069, 0.051088403517242136, 0.8635671443015304]
  > ```

## Figure 6

* best error rate performance upon different distributions in device error rate but fix data distribution on (1,1) F distribution

* the setting is the same as figure 5 except that data distribution is fixed

  > raw data:
  >
  > ```python
  > [0.04703307363136932, 0.23622493105470985, 0.49760287277868803, 0.08611855362891774, 0.2814674627485916, 0.1277660316284728, 0.05007620465775813, 0.28254735052239266, 0.08782425335745038][0.11080855616592968, 0.3370293318623937, 0.5514752850778972, 0.18053283807238268, 0.4420199317734455, 0.21785001971306303, 0.9078610356926717, 0.9184712898320901, 0.19286576933769176][0.20143531130317338, 0.5048615707723864, 0.5547478076542592, 0.18053283807238268, 0.4420199317734455, 0.1277660316284728, 0.6201308118688884, 0.9184712898320901, 0.08782425335745038]
  > ```

## Figure 7

* best error rate performance upon different distributions in data but fix device error rate distribution on (1,1) / 5 F distribution

* the setting is the same as figure 5 except that device error rate distribution is fixed

  > raw data: 
  >
  > ```python
  > [0.1368567120425945, 0.15576573860517817, 0.06860497493965667, 0.12267816616229718, 0.2596332427910961, 0.04483422115394467, 0.04778390745975467, 0.3050510894154717, 0.5510755815735606][0.2191416387440594, 0.9366884686448147, 0.7904754129480708, 0.4663520591879998, 0.8640322352278833, 0.17924105812780744, 0.31992473044151226, 0.9001581520727323, 0.6992066822808933][0.7801438598093619, 0.9317448980643426, 0.910105416332889, 0.6424392881691433, 0.9416642897221996, 0.27375548018509344, 0.36606345657918904, 0.9575793055923424, 0.9015589584708739]
  > ```

## Table

* time used by each methods

* the slowest one is SLSQP, the middle one is ranRFL, and the fastest one is GDS

* through import raw data to csv in Excel, you can see it clearly

* To be more specific: 这个表描述了算法运行时间随侯选设备数的变化关系，我们的算法在时间性能上优于SLSQP算法，劣于贪心算法，但随候选设备数增大，我们的算法运行时间仍在合理、可控的范围内

  > raw data:
  >
  > ```python
  > [0.014059209823608398, 0.01719050407409668, 0.023437690734863282, 0.024990296363830565, 0.02811589241027832, 0.029690980911254883, 0.026556968688964844, 0.032808351516723636, 0.031247878074645997, 0.03905167579650879, 0.037485289573669436, 0.031241798400878908, 0.05000548362731934, 0.0390739917755127, 0.04999217987060547, 0.05156033039093018, 0.048441100120544436, 0.05156407356262207, 0.05000307559967041, 0.05468838214874268, 0.054689621925354, 0.05155661106109619, 0.05468108654022217, 0.05780477523803711, 0.0640561819076538, 0.05624854564666748, 0.06874308586120606, 0.07186903953552246, 0.08750009536743164, 0.06718704700469971, 0.07811534404754639, 0.0798715353012085, 0.09139437675476074, 0.11626694202423096, 0.08905549049377441, 0.12340848445892334, 0.13746826648712157, 0.12965703010559082][0.0, 0.0, 0.0, 0.0015620708465576172, 0.0, 0.0, 0.001558399200439453, 0.0, 0.0, 0.0, 0.0, 0.001562356948852539, 0.0015625476837158204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001565861701965332, 0.0, 0.0, 0.0, 0.0015621423721313477, 0.0, 0.0015622377395629883, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001565241813659668, 0.0031272411346435548, 0.0, 0.0031244516372680663, 0.001562190055847168][0.017183780670166016, 0.024987053871154786, 0.03279924392700195, 0.034370827674865725, 0.0437424898147583, 0.05936057567596435, 0.04842586517333984, 0.08278958797454834, 0.06716670989990234, 0.11091492176055909, 0.09841911792755127, 0.14684040546417237, 0.1108975887298584, 0.16712429523468017, 0.1999505043029785, 0.19213566780090333, 0.19993822574615477, 0.18743271827697755, 0.2108734130859375, 0.2639873266220093, 0.3030438184738159, 0.23587255477905272, 0.26711876392364503, 0.2530567407608032, 0.2963627576828003, 0.3577136993408203, 0.29209945201873777, 0.4545668840408325, 0.38426618576049804, 0.443630313873291, 0.3967693328857422, 0.5453415155410767, 0.5831639528274536, 0.5726602792739868, 0.5186112403869629, 0.5045668363571167, 0.6061081647872925, 0.7763815879821777]
  > ```

## Conclusion

* 做了这么多对比，我们的算法就一个字——好！
* 在返回解的优越性方面，我们的算法可依赖性很高；在时间性能方面，我们的算法时间性能居中，在可以接受的范围内
* 综合来看，还是一个字——好！

> ### [引用] SLSQP—a nonlinear programming method with quadratic programming subproblems
>
> D Kraft, K Schnepper - DLR, Oberpfaffenhofen, 1989
>
> * SLSQP是一种基于梯度下降的优化算法，算法介绍可见维基百科：
>
>   https://en.wikipedia.org/wiki/Sequential_quadratic_programming